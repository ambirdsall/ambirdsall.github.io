"use strict";(self.webpackChunkambirdsall_com=self.webpackChunkambirdsall_com||[]).push([[8130],{7735:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"vanilla-js-date-formatting","metadata":{"permalink":"/blog/vanilla-js-date-formatting","source":"@site/blog/why-is-date-formatting-so-hard-in-vanilla-js.mdx","title":"Why is date formatting so hard in vanilla JS?","description":"Editor\'s note: this was written before the new, long-overdue [Temporal","date":"2024-08-05T00:00:00.000Z","tags":[],"readingTime":1.69,"hasTruncateMarker":true,"authors":[],"frontMatter":{"slug":"vanilla-js-date-formatting","title":"Why is date formatting so hard in vanilla JS?","topic":"javascript","date":"2024-08-05T00:00:00.000Z"},"unlisted":false,"lastUpdatedAt":1745535817000,"nextItem":{"title":"On that fractal triforce thing there","permalink":"/blog/on-the-sierpinski-triangle-thing"}},"content":"> Editor\'s note: this was written before the new, long-overdue [`Temporal`\\n> API](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Temporal)\\n> was announced. Better days are almost here!\\n\\nSuppose you want to deal with some dates while building a website. You don\'t want to roll\\nyour own input parsing, so you use `new Date(inputDateString)`; and you want to output\\ndatestrings in a format that\'s clear, readable[^1], and (while we\'re making a wish list)\\nsorts the same both lexically and chronologically. That is: you want `YYYY-MM-DD`. Surely\\n_that_ is built in, right?\\n\\n## wrong\\n\\nOh. Wait, really? Ugh, fine.{/* truncate */} Just `npm install date-fns` or `dayjs` or `moment` or\\n\\n## you\'re seriously going to make every user download a whole library just to create one(1) common date format with no time zone logic.\\nFINE. Fine. No.\\n\\nAt first, I was tempted to cast the date to a predictable, standardized format and then reach for ~good~ old-fashioned string manipulation:\\n```js\\nconst datestamp = date => new Date(date).toISOString().slice(0, 10)\\n```\\n\\nBut verifying the correctness of that function entails\\n1) remembering/inferring/guessing that `Date.prototype.toISOString` returns an ISO-8601-formatted date;\\n1) remembering that ISO 8601 dates start `YYYY-MM-DD`;\\n1) remembering that the ISO 8601 format zero-pads single-digit month and day fields; and\\n1) walking through a date string counting characters on your fingers like a neanderthal.\\n\\nDear reader, you deserve better than that. You deserve a built-in `strftime`-style formatting utility! But since you can\'t have that, here\'s a reasonably robust, flexible pattern you can use to extract named, semantically-meaningful parts of the date you can slep into whatever template string you want:\\n```js\\nconst datestamp = date => {\\n  const { year, month, day } = new Intl.DateTimeFormat(undefined, {\\n    year: \\"numeric\\",\\n    month: \\"2-digit\\",\\n    day: \\"2-digit\\",\\n  })\\n    .formatToParts(new Date(date))\\n    .filter(part => part.type !== \\"literal\\")\\n    .reduce((acc, part) => {\\n      acc[part.type] = part.value\\n      return acc\\n    }, {})\\n\\n  return `${year}-${month}-${day}`\\n}\\n```\\n\\n[^1]: What\'s more, you want people the world over to be able to unambiguously parse your output as _the same_ date, even if happens to be before the 13th day of its month."},{"id":"on-the-sierpinski-triangle-thing","metadata":{"permalink":"/blog/on-the-sierpinski-triangle-thing","source":"@site/blog/sierpinski-triangle-thing.mdx","title":"On that fractal triforce thing there","description":"Let\'s talk a little about how (and why) I built this:","date":"2024-05-09T00:00:00.000Z","tags":[],"readingTime":5.4,"hasTruncateMarker":true,"authors":[],"frontMatter":{"slug":"on-the-sierpinski-triangle-thing","title":"On that fractal triforce thing there","topic":"M E T A B L A G","date":"2024-05-09T00:00:00.000Z"},"unlisted":false,"lastUpdatedAt":1745535817000,"prevItem":{"title":"Why is date formatting so hard in vanilla JS?","permalink":"/blog/vanilla-js-date-formatting"},"nextItem":{"title":"Rewriting a middleman site with gatsby","permalink":"/blog/cut-out-the-middleman"}},"content":"import Triangle from \\"@site/src/components/triangle\\"\\nimport Vertices from \\"@site/src/components/vertices\\"\\nimport StaticTriangle from \\"@site/src/components/static-triangle\\"\\n\\nLet\'s talk a little about how (and why) I built this:\\n\\n<Triangle />\\n\\n{/* truncate */}\\n\\nPlay around with it a little\u2014it\'s kind of cool, right? I can never decide if I prefer the\\nsparsely- and densely-populated version.\\n\\nIt\'s also sentimental for me. Let\'s go back in time a little: in 2013, I was earning an\\nextremely meager living running an after-school art program at a local elementary school.\\nMy original dream of a tenure-track professorship in the humanities had foundered on the\\nsharp realities of the great recession and the increasingly exploitative academic job\\nmarket for teachers of every subject that lacked a corresponding industry to provide\\nnegotiating leverage. I had no clue what might be a sustainable long-term career, but I\\nknew that status quo wasn\'t it; and though I love children, after spending so many of my\\nwaking hours dealing with 10-year-olds and their  10-year-old thoughts, I could feel the\\nsharp edges of my brain beginning to dull [^1]. I needed to find something I could do with\\nmy brain that would be \\n1) difficult enough to be interesting, and\\n2) remunerative;\\n\\nand by and by my search lead me to enroll in CS101 at a local community college. I didn\'t enroll with the thought of becoming a programmer per se\u2014I just thought it would help if I ended up doing any kind of work crunching numbers. But I loved it, I was good at it, and it really did transform my life. But this isn\'t about all that: this is about an Extremely Cool demo the teacher ran one day in class.\\n\\n## The setup\\nThe teacher walked us through a very simple C++ program. It imported some graphics library\\nheaders, the details of which were glossed over (it was a 101 course, after all), and then\\ndefined a very simple initial state:\\n1) a small cartesian grid\\n1) an array of three points on that grid corresponding to the vertices of a triangle, each defined as a two-element array of `float`s\\n1) another point near the middle of the other three, assigned to a variable like `currentPoint`\\n\\nIf we were to stop here and only render the initial state, it would look something like this:\\n\\n<Vertices />\\n\\nNot very exciting yet, I admit.\\n\\n## Complex behaviors can emerge from simple rules, or: let\'s hang some mathy flesh on those bones\\nTo expand on this rather spartan, boring starting point, there was a single `for` loop, which did the following steps a few thousand times:\\n1) select a random element from the array of vertices\\n1) calculate the coordinates of the point halfway between `currentPoint` and that vertex\\n1) reassign `currentPoint` to that new point\\n1) draw the new `currentPoint`\\n\\nVery simple stuff, maybe 15 lines of code total. A well-read observer may recognize this\\nas a simple variant of [the chaos game](https://en.wikipedia.org/wiki/Chaos_game)\\nalgorithm; at the time, I didn\'t recognize shit. But I am the child of a math teacher and\\nan older millenial who has been playing Zelda games since the delirious days of Clinton vs\\nDole vs Perot, short pants, and gold NES cartridges: the teacher compiled the script, ran\\nthe binary, and it sparked joy:\\n\\n<StaticTriangle />\\n\\n## But is it Web Scale?\\nSo, we have the core algorithm for drawing a cool little fractal triforce. Now to stick in in a website!\\n\\nI made a few artistic choices:\\n1) inverting the triangle makes it look like it\'s pointing down at the content below in a nice way\\n1) naively adding points fills in the triangle with monotonically increasing density, the visual effect of which has sharply diminishing returns; pushing the points into a FIFO queue with a max size preserves the negative space it needs to look sparse, dynamic, and alive\\n1) I wanted users to be able to  interactively adjust the number of dots in the visualization: it leans into the dynamic nature of the web as a medium; it allows folks to experience both the frenetic movement and staticky geometric ambiguity of a sparsely-populated queue of points and the fractal beauty of a denser one; and it shows potential employers that I am reasonably competent at connecting user inputs to dynamic logic, which, I mean, ain\'t nothing.\\n1) The gold color (`#aa9668`, for those of you who are curious but don\'t actually want to pin down an ephemeral svg `<circle>` in your browser\'s devtools) goes nicely with the rest of the site\\n\\nThe last order of business, then, was to actually render those dots. This site is built on\\ntop of a react-based static site generator; while there is a lot to like about react, it\'s\\nnot a great choice for making performant little mathy visualizations. I decided to use d3\\nfor that. However, d3 and react both want to control the rendering of your html. How to\\nmake them play nicely together? Like this:\\n\\n```js\\nexport default function D3Wrapper({ d3RenderFn, className }) {\\n  // d3 needs an actual DOM node to do its thing on, so let\'s give it one\\n  const el = useRef(null)\\n\\n  // Render the d3 visualization. If the d3 visualization is already in the DOM, though,\\n  // do not recreate it; this avoids duplicated element shenanigans with hot module\\n  // reloading during development.\\n  useEffect(() => {\\n    if (!window.d3Embeds) {\\n      window.d3Embeds = new Map()\\n    }\\n\\n    if (!window.d3Embeds.get(d3RenderFn)) {\\n      d3RenderFn(el.current)\\n      window.d3Embeds.set(d3RenderFn, true)\\n    }\\n  }, [d3RenderFn])\\n\\n  return <div className={className} ref={el} />\\n}\\n```\\n\\nAnd really, that\'s it. A cute little bit of web-based art that makes me happy.\\n\\n[^1]: I should note here that this is not a fundamental fact of dealing with kids: parents and school teachers have the chance (the obligation, even) to engage more deeply with their kids, and tracking those longer-term educational goals to the kids\' intellectual and emotional development provides as deep an intellectual challenge as you care to make it. Hanging out for two hours doodling on butcher paper and helping with the stultifying abolination that is second-grade homework [^2], though? I needed more.\\n\\n[^2]: Up until _at least_ the start of adolescence, children\'s intellectual and social development requires free, exploratory play, not rote drilling of skills; and their emotional and executive regulation is not strong enough to get any long-term benefit from the discipline of finishing their daily assignments. But by all means, if you want to force parents to force their kids into boring, tedious chorework, keep it coming!"},{"id":"cut-out-the-middleman","metadata":{"permalink":"/blog/cut-out-the-middleman","source":"@site/blog/blog-rewrite.mdx","title":"Rewriting a middleman site with gatsby","description":"It came to pass that after 3 years of neglect, I wanted to revive my old","date":"2019-12-05T00:00:00.000Z","tags":[],"readingTime":7.435,"hasTruncateMarker":true,"authors":[],"frontMatter":{"slug":"cut-out-the-middleman","title":"Rewriting a middleman site with gatsby","topic":"M E T A B L A G","date":"2019-12-05T00:00:00.000Z"},"unlisted":false,"lastUpdatedAt":1745535817000,"prevItem":{"title":"On that fractal triforce thing there","permalink":"/blog/on-the-sierpinski-triangle-thing"},"nextItem":{"title":"Why emacs is worth the bother","permalink":"/blog/why-emacs-is-worth-the-bother"}},"content":"It came to pass that after 3 years of neglect, I wanted to revive my old\\nwebsite. I figured I\'d add a post or two, maybe tweak a few things about the\\nHTML and CSS, and then I could rewrite it in a different stack at my leisure.\\nI think a lot of things that are wrong, though.\\n\\n{/* truncate */}\\n\\n## Problem: I had a new computer and my webpage had a fussy development env;\\n\\nI tried to run the development build, but ran into an error: I needed the right\\nruby version. I\'ve never done ruby development on this operating system, so I\\ndon\'t have any tool in place to manage ruby versions. To fix things, I needed to\\ninstall one of `chruby`/`rbenv`/`rvm`; setup `nix` or `guix` with `direnv`; or\\nmaybe I could use `asdf` or fuck if I know what the cool kids are doing these\\ndays. Oy, what a hassle. Still, I eventually got on the version of ruby\\nspecified in the Gemfile and I got a different error. Progress, right?\\n\\nI needed to upgrade bundler, so I ran `bundle update --bundler`. This, it seems,\\novershot the mark: I needed to downgrade bundler, which is a bigger hassle than\\nupgrading. Whatever: I uninstalled the new version and installed the specific\\nolder one that was compatible with the rest of the project.\\n\\nWith this, I could actually run the site locally! All was not well, though: it\\nlooked like crap. It turned out that only some of the stylesheets I was loading\\nfrom a ruby gem were available in practice, and the icon font I had been using\\nwas nowhere to be found[^1]. At this point, I gave up: none of these problems were\\ninsurmountable, but why go to all that effort when I wanted to rewrite it\\nanyway?\\n\\n## and, having been exposed to JSX,\\n\\nIn the ruby version, I used `.erb` files to handle dynamic data and a few bits\\nof html boilerplate. The way `.erb` files treat the non-logic contents as a dumb\\ntext stream, not something with a tree structure, makes it fundamentally a worse\\nfit for modeling HTML than the tree structure of JSX templates[^3]. Having\\nworked with react and angular, I don\'t want to go back to the bad old days of\\nwrangling HTML as raw text, I want to compose and encapsulate HTML using\\ncomponents; and having used JSX, embedding the structural logic of the template\\nwithin the content has begun to feel inside out. I didn\'t want to use another\\ntemplating system.\\n\\n## and wanting to maintain a statically-generated site,\\n\\n(While `create-react-app` is dope and all, there is zero dynamic content on this\\nwhole site.)\\n\\n## the choice of gatsby seemed good, so I set to work.\\n\\nFirst I made the page shell; that was just porting some html to react\\ncomponents. It happened that all I needed were well-documented, [easily\\nsearchable plugins](https://www.gatsbyjs.org/plugins/) to [render\\nmarkdown](https://www.gatsbyjs.org/packages/gatsby-transformer-remark/)\\ninto pages via a template; with [colorized code\\nblocks](https://www.gatsbyjs.org/packages/gatsby-remark-prismjs/);\\nwith [autolinked\\nheaders](https://www.gatsbyjs.org/packages/gatsby-remark-autolink-headers/);\\nwith\\n[footnotes](https://www.gatsbyjs.org/packages/gatsby-remark-footnotes/).\\n\\nAs a sidenote, pour one out for good sidenotes. I\'m still holding out hope I\\nfind a decent plugin I can use to finagle sidenotes from markdown without\\nneeding to go all the way on some Tufte CSS theme. I don\'t think I\'m likely to\\ngo to the effort of coding one up myself anytime soon, though.\\n\\nAnyway, I had the existing posts rendering acceptably to HTML from pure\\nmarkdown, getting autolinking and asides without needing any .erb equivalent.\\n\\n## I had to figure out how to sort a list of posts;\\n\\nThis was straightforward: I wanted to group by topic, sort each topic by date,\\nand sort the set of topics by date of most recent post. All the data I needed\\nwas easily queryable from the markdown frontmatter via graphQL. You\'ll notice\\nthat the remark plugin which renders the markdown exposes the list of rendered\\nposts under a property named `edges` and, to be honest, I\'m not sure why: the\\nname seems to describe the data\'s underlying topology rather than its API.\\nWhatever.\\n\\n```javascript\\n// the page component\'s props are destructured like so:\\n// ({\\n//   data: {\\n//     allMarkdownRemark: { edges },\\n//     site: { siteMetadata: { title }},\\n//   },\\n// })\\nconst postsByTopic = edges\\n  .filter(e => !e.node.frontmatter.draft)\\n  .map(e => e.node)\\n  .reduce((topics, n) => {\\n    const { topic } = n.frontmatter\\n\\n    // nobody likes to evaluate `undefined.push(n)`\\n    topics[topic] = topics[topic] ? topics[topic] : []\\n\\n    topics[topic].push(n)\\n    topics[topic].sort((a, b) => newestFirst(a, b))\\n\\n    return topics\\n  }, {})\\n\\n// Order the topics by date of most recent post\\nconst Posts = Object.values(postsByTopic)\\n  .sort((a, b) => newestFirst(a[0], b[0]))\\n  .map(renderSingleTopic)\\n```\\n\\nBefore you ask, yes, I know that sorting topics each time a new post is added is\\nan `O(n\xb2)` algorithm, yes, I know that\'s improvable, and no, I don\'t care to\\nmake it more efficient: posts are sorted once at build time, and I\'d have to\\npublish a post ever day for years (if not decades) before that `n` gets big\\nenough to be a problem. When efficiency is not important, always take the\\napproach that\'s simplest to understand.\\n\\nI found it was significantly nicer to do the filtering in javascript than ruby.\\nI was surprised by that, because I really love ruby\'s `Enumerable` methods. But\\njs objects are up with cons cells among my very favorite data structures to work\\nwith, first-class functions make custom sorting comparators easy to add as\\narguments, and `Array.prototype` methods are just as chainable as\\n`Enumerable`s[^4]. The definition of that `newestFirst` comparator function is\\nleft as an exercise to the reader, that\'s already a fair chunk of code.\\n\\n## then how to update the d3 triangle thing to modern d3 using es6 imports\\n\\nThis wasn\'t too bad: I changed all the `var` statements to `const`; fixed the\\none variable I mutate in place (it\'s the easiest way to implement the algorithm)\\nto use `let` instead; and imported `d3`. Modern versions of `d3` export their\\nconstituent parts as named exports, for ease of tree-shaking, so I had change\\nthe code to import the functions I actually used instead of relying on the `d3`\\nobject to have everything. `d3.scale.linear()` had become `d3.scaleLinear()`,\\nbut otherwise this was a pretty mechanical translation.\\n\\n## then how to embed a d3-controlled element in a react component\\n\\nFiguring this part out was kind of fun! The basic 2-step to mounting a\\nself-contained `d3` visualization inside of a react app:\\n\\n1. `const domElementRef = useRef(null)`\\n2. `useEffect(() => d3.select(domElementRef.current).doStuffWith(props.data), [props.data])`\\n\\nThat\'s the general approach, since usually a `d3` visualization is based on some\\ninput data and should rerender when and if the data changes; mine uses\\nrandomly-generated data, though, so I didn\'t even need the dependency array.\\n\\nRegardless, it\'s much nicer to do with hooks than lifecycle methods, where you\'d\\nneed to use both `componentDidMount` and `componentDidUpdate` to ensure the\\nvisualization ran at all the appropriate times.\\n\\n## and then I had a site!\\n\\nI hope you like it.\\n\\n[^1]:\\n\\n  It is very popular to try to dunk on the javascript ecosystem in various parts\\n  of programmer culture[^2], and one of the very most popular ways is to clown on\\n  the size of the `node_modules` directory. Since `npm` installs every package on\\n  a per-project basis; since it errs on the side of having multiple (potentially\\n  incompatible) versions of transitive dependencies rather than forcing you to\\n  just choose one; and since javascript itself has a very small standard library,\\n  leading to heavy use of library code; it\'s common to have large `node_modules`\\n  directories on your hard drive. Clown all you want, but the self-containment of\\n  that approach would have saved me a bunch of hassle here. Or maybe I just had a\\n  badly-written `Gemfile`.\\n\\n[^2]:\\n\\n  I have the strong impression that this is at least in\\n  part sub-rosa sexism: frontend work, being user-facing and visual, fits\\n  stereotypes of women\'s work, and indeed many female programmers are channeled\\n  into frontend work regardless of their specific interests or abilities.\\n  Neckbeards huddle together discussing the manly arts of functional programming,\\n  asynchronous logic, optimizing dependency graphs, and distributed computing,\\n  never pausing to consider that those are all part and\\n  [parcel](https://parceljs.org/) of frontend work. But I digress.\\n\\n[^3]:\\n\\n  I have an intuition that this has to do with the ol\' Chomsky hierarchy,\\n  akin to how regular expression can scan text streams in sophisticated ways but\\n  can\'t validate structural features like valid nesting or pairing.\\n\\n[^4]:\\n\\n  A rant: what the fuck is up with how `sort` mutates the array in place?\\n  It\'s totally out of character with the rest of the `Array.prototype` chainable\\n  methods, which return new arrays, and its idiosyncracy offers no benefit: it\'s\\n  just a footgun which makes it easy to mutate your application data behind your\\n  own back. I realize backwards compatibility means we\'re stuck with a mutating\\n  `sort`, but I really do think the next iteration of the language should add a\\n  new `Array.prototype.sorted` method which returns a new sorted array."},{"id":"why-emacs-is-worth-the-bother","metadata":{"permalink":"/blog/why-emacs-is-worth-the-bother","source":"@site/blog/emacs-intro.mdx","title":"Why emacs is worth the bother","description":"Emacs has a few unusual properties which work together really well, making for a","date":"2019-12-02T00:00:00.000Z","tags":[],"readingTime":12.325,"hasTruncateMarker":true,"authors":[],"frontMatter":{"slug":"why-emacs-is-worth-the-bother","topic":"emacs","title":"Why emacs is worth the bother","date":"2019-12-02T00:00:00.000Z"},"unlisted":false,"lastUpdatedAt":1745535817000,"prevItem":{"title":"Rewriting a middleman site with gatsby","permalink":"/blog/cut-out-the-middleman"},"nextItem":{"title":"Zero-friction testing in rails","permalink":"/blog/zero-friction-testing-in-rails"}},"content":"Emacs has a few unusual properties which work together really well, making for a\\nsuper powerful, flexible system that\'s easier to bend to your will in\\nsophisticated ways than almost anything else around. That might sound like a lot\\nof work, but most day-to-day emacs usage isn\'t reinventing the world; when you\\nwant to do something custom, though, the power is right at your fingertips.\\nLiterally.\\n\\n{/* truncate */}\\n\\nWhat are those properties? Well:\\n\\n1.  Emacs is configured with a full-fledged, high-level programming language,\\n    with functions, control flow, etc. Emacs lisp is a dynamic functional\\n    language; the syntax is out of the ordinary, but under the hood, it\'s a\\n    little like old-school javascript with an emphasis on linked lists, strings,\\n    and text buffers. Except for macros, which are powerful like magic, only\\n    less&#x2026; magical.\\n\\n2.  Literally everything you can do in emacs, including really basic stuff like\\n    \\"move the cursor forwards 15 characters\\" and \\"insert the text `function fo() { return \\"haha this was not named foo\\" }`\\" can be scripted with emacs lisp.\\n    Here:\\n\\n    ```emacs-lisp\\n    (forward-char 15)\\n    (insert \\"function fo() { return \\\\\\"haha this was not named foo\\\\\\" }\\")\\n    ```\\n\\n3.  Literally every user interaction follows the same model: you hit a key (or\\n    equivalent, like clicking the mouse), which triggers some lisp function.\\n\\n4.  You can look up, at any time you want, the name of the function bound to any\\n    key; the full documentation for any function (with a hyperlink to its source\\n    code, so you can dig as deep as you want); and the value of any variable.\\n    Just type `C-h` and then one of `k`, `f`, or `v` (guess which is which).\\n    (There are lots more help options under that `C-h` prefix, too.)\\n\\n5.  Literally any keystroke and combination can be bound to any function you\\n    want.\\n\\nI know I used \\"literally\\" a lot in there, but lots of programs make sweeping\\n\\"[verb] any [noun]!\\"-type claims that are only _mostly_ true.\\n\\nAnyway, once you internalize the logic of this system, you have superpowers! Did\\nsomething weird just happen? Type `C-h k`, then hit the same keystroke again to\\nfind out what function is responsible. Want to change what that keystroke does?\\nYou can, on the fly. You always open the same file, so you want a shortcut?\\nThat\'s like a 30-second customization, once you\'re used to emacs. Want to do\\nsomething fancy, but you don\'t know what the right function is named? Just\\nsearch for all the available function names with `C-h f`, and if one sounds\\nright, select it to check its documentation. Faster than google, and always, by\\ndefinition, up-to-date with your specific emacs instance.\\n\\nEmacs has a lot of janky and/or bullshit characteristics, due to its long\\nhistory, survivor bias, and occasionally just due to the intransigence of the\\nmaintainers (if any emacs maintainers read this, a sincere thank you for all you\\ndo and all you have done! Now please, for the love of humans, approve some PRs\\nto make the default UI more beginner-friendly and update its looks). No emacs\\nuser is beholden to those neckbeards, though: if you don\'t like it, you can\\nchange it. Or if you\'re not feeling like all that work, you can usually find\\nsomeone else who already changed it the way you want and put that shit on\\ngithub.\\n\\n## seriously, before you get started: remap caps lock to control\\n\\nCaps lock is useless. Control is _constantly_ used in emacs. As a bonus, lots of\\nstandard emacs shortcuts for text navigation (`C-a` to jump to start of line;\\n`C-e` to jump to end of line; `C-k` to delete from the cursor to the end of text\\nor the next newline, whichever comes first; `C-t` to \\"transpose\\" two characters\\nwhen you make a tyop; `C-n` and `C-p` to go down/up one line) work in the shell\\nand in almost all OSX text fields. If control is where caps lock was, all this\\nis right on home row, super easy and ergonomic to use. If not, you sort of end\\nup making weird claw hands all the time.\\n\\n## okay, with that out of the way: quick start\\n\\nLots of people will tell you that stock emacs sucks. That is because stock emacs\\nkind of sucks. We can do better than that.\\n\\n### Install a version of emacs that isn\'t awful\\n\\nIf you\'re on a mac, there is an `emacs` pre-installed, but it\'s like 10 years\\nout of date and only works in the terminal. It\'s good for one thing:\\n\\n```shell\\n# haha, good luck figuring out how to close emacs\\nemacs -q --no-splash -f tetris\\n```\\n\\nTetris? Remember, you can rebind any keystroke to run your own code, and emacs\\nwill do any song and dance you\'re clever/patient enough to write. Web browsers\\nwere originally just for viewing documents, too.\\n\\nFor your non-tetris needs, you\'ll want to do one of these\\n\\n```shell\\n## good, but ought to be better\\nbrew install emacs\\n\\n## much better, unless connecting to your running emacs from the terminal is important to you\\n## (and if it is, you probably don\'t need introductory notes?)\\nbrew tap railwaycat/emacsmacport\\nbrew install emacs-mac\\n```\\n\\nWhy is the normal emacs not the best choice for mac? Because the Free Software\\nFoundation people are assholes about everything but linux. Sorry, \\"GNU/linux\\".\\nSo some guy forked emacs so he could add e.g. native OSX smooth scrolling and\\nshit.\\n\\n### Install a starter kit\\n\\nThese have gotten popular these days. Basically, these are community-maintained\\nconfigurations on top of emacs. They add in useful third-party libraries (in\\nsome cases, so useful they have become de facto standards), update the styling\\nso emacs looks like it\'s from the present, instead of the mid-90s, and usually\\noffer a bunch of variables you can tweak to easily toggle features and stuff.\\nThey\'re generally intended to be a more powerful and beautiful \\"batteries\\nincluded\\" starting point for people. To install a starter kit, just clone the\\nproject repository to `~/.emacs.d`; when you next start emacs, it will\\nautomatically load that code.\\n\\n#### If you like pi\xf1a coladas, and getting stuck in a vim session\\n\\nMy favorite is [doom emacs](https://github.com/doomemacs/doomemacs). It\'s quite possibly the most\\npopular, with excellent documentation and community. Doom is written by and for people who like vim\'s\\ncommand language (which is an insanely good fit for emacs\' keybinding model,\\nactually), but you don\'t need to use it in a vimmy way. Most people do, because\\nit\'s insanely good like that, but you do you. Doom has a wonderful system\\nof mnemonic commands that you access via a universal prefix key (inspired by [spacemacs](https://github.com/syl20bnr/spacemacs), which is also quite good), which is the\\nspace bar if you use vim keybindings and something else if you don\'t. Even if you choose\\nnot to use vim bindings at all, I\'d recommend doom: the out-of-the-box experience is miles\\nbetter than stock emacs, it\'s well-organized and documented, and Henrik\'s hand-rolled,\\nnix-inspired package management system absolutely shines if you ever want to keep things\\nin sync between a personal and work computer.\\n\\n#### If you want something more traditionally emacsy, because you don\'t give a fuck about vim\\n\\nA venerable starter kit that\'s a bit more mainline emacs is\\n[Prelude](https://github.com/bbatsov/prelude). I haven\'t used it, so I can\'t comment on it\\nmuch, but I\'ve heard very good things, and its primary maintainer is pretty legit.\\n\\n#### If you want to be FANCY\\n\\nA new one is [Centaur](https://github.com/seagle0128/.emacs.d). Centaur is very\\npretty and into normal modern UI stuff like file trees with icons and tabs and\\nstuff.\\n\\nOh yeah, emacs doesn\'t really even have decent tab support? At the time of\\nwriting, in the year of our lord 2019, it\'s only a first-class UI feature in the\\ncutting edge versions and hasn\'t even made it to a stable release. Centaur tabs\\nare clever, but a hack. I dunno, y\'all, nothing\'s perfect.\\n\\nCool, you have a modern version of emacs, and now it looks adequate. Let\'s get\\noriented.\\n\\n### A quick tour of essential emacs keybindings\\n\\nYou can remap any key in any mode, but the defaults are around until and unless\\nyou change them, so they\'re worth knowing. I\'m assuming you didn\'t install\\nspacemacs in vim mode; if you did, a few parts of this won\'t generally apply.\\n\\nBy convention, emacs documents keystrokes (in all of its documentation and when\\nreporting what keys a function is bound to) a certain way. I\'ve already used it\\nabove. Here\'s a more complicated keybinding:\\n\\n```\\nC-x c\\n```\\n\\nThis means \\"hold control and type x; then type c\\". You never hit control except\\nin combination with other keys, so the \\"c\\" character is unambiguous in both\\nspots there. In keybinding notation, dashes mean \\"hit these two keys together\\"\\nand spaces mean \\"after typing key X, release the keys and then type key Y\\".\\n\\nTwo modifier keys are king in emacs: control, which is the control key, and\\nmeta, which is the alt key. It\'s weird, but emacs literally predates the alt key\\nbeing standard. Meta is `M-[something]` in keybinding notation.\\n\\nIf you\'re a hipster like me, you might switch things up so that the mac command\\nkey is meta instead of alt. Emacs is what you make it.\\n\\n#### First command to learn: `M-x` lets you run commands by name\\n\\nA decent starter configuration will give you a nice fuzzy search interface when\\nyou hit `M-x`. Start typing, and when the command you want comes up in the\\nresults, you can use the arrow keys and enter to execute that command. Don\'t\\nremember the keybinding for some functionality? Hit `M-x` and start typing its\\nname. Since keyboard space is finite, some commands can only be run like this.\\nFor example, `M-x snake` starts a game of snake, and `M-x doctor` starts a\\npsychotherapy session with everyone\'s favorite 1960s chatbot ELIZA.\\n\\n#### First commands to learn: what to do when you panic\\n\\n`C-x C-c` closes the program. It\'s good to know, especially if you run it in a\\nterminal.\\n\\nWithin a session, if emacs freezes, or starts acting weird, or you mistype and\\nfind yourself halfway into the wrong key sequence, start spamming `C-g` to\\ncancel out of whatever the current thing is. The downside to letting people run\\ntheir own code is that sometimes they write dumb code and have stuff like\\ninfinite loops. In cases like this, `C-g` is your friend. You can also spam the\\nescape key: on the rare occasion `C-g` doesn\'t work, three escapes usually will.\\n\\n#### There\'s a method to the madness\\n\\nReally quick commands you will do while you type code/prose/emails/whatever are\\nbound to control [something] or meta [something], so you can just bust them out\\nquickly. Commands that are common but that you\'re less likely to use in quick\\nsuccession, like saving, managing your windows, quitting emacs, etc, are under\\nthe `C-x` prefix (the \\"x\\" is for \\"execute command\\": Emacs tries to make stuff\\nmnemonic). Commands that are less common than that (or when you remember the\\nname but not the keybinding), you can type `M-x` and find them by name. The\\nsimilarity of the two \\"execute command\\" keybindings, `C-x` and `M-x,` is not a\\ncoincidence. Mnemonic, remember?\\n\\nThat\'s a decent intro to the standardish sort-of-hierarchy for what different\\nmodifier keys mean with the same key. `C-f` goes forwards one character; `M-f`\\ngoes forwards one word; `C-M-f` goes forward one semantic unit (paired quotes or\\nbraces, a code block, or whatever: different language modes can define what a\\nsemantic unit is, and emacs has some more-or-less sensible global defaults).\\nWhen \\"same thing, but with a wider scope\\" doesn\'t make sense, sometimes control\\nand meta do opposite versions of the same thing. I don\'t want to bog you down\\nwith examples, though: you can get by for a while using arrow keys, the mouse,\\nand a small handful of memorized commands.\\n\\nThe file menu is a nice way to find commands at first, too, though you\'ll\\nprobably leave it behind as you internalize a more keyboard-driven workflow.\\n\\n### what is a mode, even\\n\\nModes are how emacs lets you apply or remove related configurations and\\nkeybindings en masse. Functions that manipulate ruby code only make sense if\\nyou\'re editing a ruby file; so those keybindings only apply when `ruby-mode` is\\nactive. `ruby-mode` is a _major_ mode.\\n\\nEvery buffer has one (1) major mode. This says what kind of thing that buffer\\nis. Is it a file of some programming language? Each programming language has its\\nown major mode (sometimes you even have a couple options, because open source).\\nIs the buffer an interactive feature, like a game of tetris or a git dashboard?\\nIs it some elisp function\'s documentation? That\'s the major mode. You can use\\n`M-x` to change the major mode (they\'re just functions, under the hood), and\\ninteract with the buffer contents in a different way, but you almost never have\\nto.\\n\\nYou can only have one major mode per buffer, but you can have as many minor\\nmodes as you want. Minor modes tend to wrap a few related functions and settings\\ninto some feature, so you can easily toggle the feature by (de)activating the\\nminor mode. Autocomplete is a minor mode. Spell-check is a minor mode.\\n[rainbow-mode](https://elpa.gnu.org/packages/rainbow-mode.html) is a minor mode,\\nand makes writing CSS so much nicer. A [nyan cat status\\nbar](https://github.com/TeMPOraL/nyan-mode) to tell you how far into a buffer\\nyou are? Minor mode. Most features are implemented as minor modes.\\n\\n### [one of] the killer app[s]: org-mode\\n\\n`org-mode` is sort of like markdown on steroids. You can rearrange the order and\\nlevel of headings interactively on the fly; edit code snippets as if they were\\nactual files, with full language support; edit tables like a spreadsheet; export\\nyour notes to pdf, html, LaTeX, github-flavored markdown (although github parses\\n`.org` files just like it does `.md` ones), or a reveal.js slideshow; and so, so\\nmuch more. I wrote this page as some quick-and-dirty notes in `org-mode`\\n(seriously: if you replace `index.html` with `index.org`, you can see the raw\\nsource). `org-mode` started out life as a third-party package for emacs, but it\\nis so good and became so popular that it\'s included with emacs now.\\n\\nThe basics (slightly different markdown with magic table formatting and built-in\\ntodo list support!) are simple to learn and legitimately powerful on their own;\\nbut its feature set is so deep, you can spend years learning it and still not\\nknow everything. Even if you never use emacs for anything else, `org-mode` is\\nworth it.\\n\\nHonest-to-god: take 30ish minutes of your life (you don\'t need to watch the Q\\nand A for pete\'s sake) and watch this presentation that Carsten Dominik, the\\nGerman astronomer who authored org-mode, gave at google:\\n\\n<iframe width=\\"560\\" height=\\"315\\" src=\\"https://www.youtube.com/embed/oJTwQvgfgMM\\" frameBorder=\\"0\\" allow=\\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\\" allowFullScreen></iframe>"},{"id":"zero-friction-testing-in-rails","metadata":{"permalink":"/blog/zero-friction-testing-in-rails","source":"@site/blog/zero-friction-testing-in-rails.mdx","title":"Zero-friction testing in rails","description":"AUTHOR\'S NOTE: this post is several years old, but it\'s a fun time","date":"2016-12-09T00:00:00.000Z","tags":[],"readingTime":6.06,"hasTruncateMarker":true,"authors":[],"frontMatter":{"slug":"zero-friction-testing-in-rails","title":"Zero-friction testing in rails","topic":"testing","date":"2016-12-09T00:00:00.000Z"},"unlisted":false,"lastUpdatedAt":1745535817000,"prevItem":{"title":"Why emacs is worth the bother","permalink":"/blog/why-emacs-is-worth-the-bother"},"nextItem":{"title":"Building An Adequate Wedding Gallery","permalink":"/blog/building-an-adequate-wedding-gallery"}},"content":"> **AUTHOR\'S NOTE:** this post is several years old, but it\'s a fun time\\n> capsule. Professionally I was but a babe, and had just left one of my first\\n> programming jobs, where I had encountered my first truly heinous codebase. I was\\n> almost comically thirsty for quality and blessed with a project that was\\n> conceptually reducible to a pure function. Nonetheless, what is describes\\n> remains my favorite programming workflow: in a split terminal window, running\\n> a text editor on one side, with a unit test watcher on the other side giving immediate\\n> feedback when files change.\\n\\nSo. It wasn\'t until a few months ago that I finally worked on a software\\nproject with full test coverage. Now that I have, I\'m a little shocked and\\nhorrified it took this long: the quality of life is drastically better on\\nthis side. The project in question is [RIO](https://law.cornell.edu/rio), an\\nES6 legal citation parser I\'ve been building for Cornell Law\'s LII. I\'ve been\\ndeveloping that solo, so I had the liberty of setting the testing mantle up to\\nsuit my own workflow: heavily terminal-based, using vim and tmux.\\n\\n{/* truncate */}\\n\\nI\'ve found that it\'s a massive help to be able to have tests constantly\\nrerunning in a splitscreen with vim every time I save a file. The constant\\nfeedback means I don\'t need to keep switching mental context to see if my code\\nis correct: I can, while still in my editor, just glance over at a current test\\nrun. This has utterly revolutionized how I feel about refactoring: knowing\\nexactly when my code breaks and unbreaks as I rearrange things is a massive\\nhelp for refactoring, and reveals bugs pretty much the instant they are\\nintroduced. I haven\'t had to write a `debugger` in anger in a shockingly long\\ntime. I want that confidence and speed when I work on rails projects, too.\\n\\nSo, to recap, I want\\n\\n1. fast tests that\\n1. run automatically on file save\\n1. run by a persistent server I can ogle in a tmux split while I vim away in\\n   the same terminal window.\\n\\n## Fast tests\\n\\nThe speed can be helped by `spring`, a gem that comes in rails\' default\\n`Gemfile` but which takes a bit of setup. Once you _have_ set it up, though,\\nit\'s brilliant. After the first command which requires loading your rails app,\\n`spring` keeps running as a background process, with your application\\nenvironment loaded into memory. This means that the next time you run a command\\nthat requires a loaded app, like your test suite, you get to skip the\\nseveral-second wait for rails to bootstrap itself\xadyou only need to run\\nthe test files themselves. Out of the box, `spring` only knows how to wrap the\\n`rails` and `rake` commands to use the preloaded app, but the\\n`spring-commands-rspec` gem expands that set to also wrap `rspec`, which I\'m\\nusing for my tests.\\n\\nIncidentally, I\'ve read things which assert that `minitest` is a good bit\\nfaster than `rspec`; but `rspec` has quite a lot of community support, and I\'ve\\nbeen writing a ton of `jasmine` tests lately, which has wicked similar syntax.\\nThe point of this is to lower the cognitive load of testing, after all. With a\\nmassive test suite, though, the time savings might be worth switching over. As\\nalways, measure: the old command-line standby `time` is your friend.\\n\\n## Running automatically on file save\\n\\n`guard` is the gem of choice here. It reads a `Guardfile` in the root of your\\nproject: in that `Guardfile`, which is written in a ruby DSL, you define what\\nactions `guard` should run for given project files and which files to ignore.\\nIf you, like I, are on osx, you should also install `rb-fsevent`, which makes\\n`guard` listen to osx\'s native FSEvents API instead of having to poll the disk\\nfor changes (which is slower and takes more work from your CPU). You can\\nspecify any command-line callback you like in your `Guardfile` with backticks,\\nbut there are quite a few guard plugins that automatically set up conventional\\nrules for a conventional rails configuration and tool-specific configuration\\noptions. Enter `guard-rspec`.\\n\\nHere are the versions of all the gems I used when I went through this myself,\\nif you\'re into that sort of thing:\\n\\n```\\nguard 2.14.0\\nguard-rspec 4.7.3\\nrails 4.2.5\\nrb-fsevent 0.9.8\\nruby 2.3.1\\nspring 2.0.0\\nspring-command-rspec 1.0.4\\n```\\n\\n## Let\'s set these bad not-specifically-gendered children up\\n\\nIn your `Gemfile`:\\n\\n```ruby\\ngroup :development, :test do\\n  gem \'spring-commands-rspec\'\\n  gem \'rspec-rails\'\\n  gem \'guard-rspec\'\\n  gem \'rb-fsevent\' if `uname` =~ /Darwin/\\nend\\n```\\n\\nAnd\\n\\n```shell\\nbundle\\n```\\n\\n## Setup Spring\\n\\nTo generate the command wrappers necessary to use the preloaded app, run\\n\\n```shell\\nspring binstub --all\\n```\\n\\nwhich should generate some output along the lines of\\n\\n```shell\\n* bin/rake: spring inserted\\n* bin/rspec: spring inserted\\n* bin/rails: spring inserted\\n```\\n\\nIf you forgot to rebundle before running this or otherwise need to change the\\nconfiguration for `spring`, you\'ll need to stop and restart `spring` with\\n\\n```shell\\nspring stop\\n```\\n\\nOtherwise, it will keep reusing the old outdated preloaded environment. And, if you\'re paranoid:\\n\\n```shell\\nspring status\\n```\\n\\nFor those quick tests I mentioned, just run\\n\\n```shell\\nbin/rspec\\n```\\n\\n`bin/rspec` is the wrapper script genreated back in the `spring binstub --all`\\nstep. You could also run `rspec` through `spring` manually with\\n\\n```shell\\nspring rspec\\n```\\n\\nLife is full of choices, and many of them don\'t matter. I timed both on some\\nempty spec files I scaffolded (with test output truncated, of course):\\n\\n```shell\\n% spring stop\\nSpring stopped.\\n\\n% time bin/rspec\\n\\n[...]\\nFinished in 0.66145 seconds (files took 0.61181 seconds to load)\\n32 examples, 0 failures, 18 pending\\n\\nbin/rspec  0.25s user 0.06s system 4% cpu 6.348 total\\n\\n% time bin/rspec\\n\\n[...]\\nFinished in 0.59806 seconds (files took 0.58837 seconds to load)\\n32 examples, 0 failures, 18 pending\\n\\nbin/rspec  0.27s user 0.09s system 19% cpu 1.864 total\\n\\n% spring stop\\nSpring stopped.\\n\\n% time spring rspec\\n\\n[...]\\nFinished in 0.58927 seconds (files took 0.36102 seconds to load)\\n32 examples, 0 failures, 18 pending\\n\\nspring rspec  0.27s user 0.09s system 5% cpu 5.996 total\\n\\n% time spring rspec\\n\\n[...]\\nFinished in 0.57317 seconds (files took 0.34346 seconds to load)\\n32 examples, 0 failures, 18 pending\\n\\nspring rspec  0.27s user 0.08s system 25% cpu 1.398 total\\n```\\n\\nEither way, `spring` made the tests _much_ faster after the first run, and\\nthose savings persist so long as the spring server is running.\\n\\n## Setup Guard\\n\\nI assume you already ran\\n\\n```shell\\nrails g rspec:install\\n```\\n\\nbut if you didn\'t yet, do. Then run\\n\\n```shell\\n% guard init\\n\\n01:34:28 - INFO - Writing new Guardfile to /Users/ambirdsall/code/rails/event_scheduler/Guardfile\\n01:34:28 - INFO - rspec guard added to Guardfile, feel free to edit it\\n```\\n\\nFind this line of your new `Guardfile`:\\n\\n```ruby\\nguard :rspec, cmd: \\"bundle exec rspec\\" do\\n```\\n\\nand change it to\\n\\n```ruby\\nguard :rspec, cmd: \\"bin/rspec\\" do\\n```\\n\\nNICE.\\n\\n## There you go\\n\\nNow just fire up `guard` with the command `guard`. Shazam! Your tests will run on save.\\n\\nThe little prompt `guard` gives you is an interactive ruby console, too, which\\nis really handy for double-checking the syntax of quick snippets when fixing\\ntest failures. Use Ctrl-d to kill it, or just close your terminal."},{"id":"building-an-adequate-wedding-gallery","metadata":{"permalink":"/blog/building-an-adequate-wedding-gallery","source":"@site/blog/building-an-adequate-wedding-gallery/index.mdx","title":"Building An Adequate Wedding Gallery","description":"A Cool-ass photo album","date":"2016-11-29T00:00:00.000Z","tags":[],"readingTime":4.165,"hasTruncateMarker":true,"authors":[],"frontMatter":{"slug":"building-an-adequate-wedding-gallery","title":"Building An Adequate Wedding Gallery","topic":"ruby","date":"2016-11-29T00:00:00.000Z"},"unlisted":false,"lastUpdatedAt":1745535817000,"prevItem":{"title":"Zero-friction testing in rails","permalink":"/blog/zero-friction-testing-in-rails"},"nextItem":{"title":"Cron: Legacy","permalink":"/blog/cron-legacy"}},"content":"## A Cool-ass photo album\\n\\nOur wedding photographer was a little slow in getting us our images, so I got\\nto thinking about what to do. I decided I wanted a static image gallery, and I\\nwanted it to be easy for anyone who came to get copies of photos they like,\\nwhether for online use or making prints. For prints, people should be able to\\ndownload the high-resolution originals, and those are such big files, it makes\\nsense to zip the files before downloading. For digital use, there should be\\nsmaller image files for download[^1],\\nbut that could easily be handled entirely client-side.\\n\\nI decided that, in addition to normal \\"download this photo\\" usage, I wanted the\\nability to\\n\\n1. Select any given subset of the images easily; and\\n1. Download that set of images as a zip file\\n\\nThis is a kinda fun UI problem AND has a fun backend problem despite dealing\\nwith static data. Which is great: since we\'re not barring our photos from\\nanyone, there\'s no need to implement any auth, which cuts out a big, common hassle right\\nfrom the get-go.\\n\\n{/* truncate */}\\n\\nThe zipping part means there needs to be some server code running; I decided to use\\na rails app hosted on elastic beanstalk. I was already hosting the images on\\ns3, and AWS designs all their services for easy interop (naturally, to keep all\\nyour money going their way); besides, I had never hosted an app that way and I\\nwanted to learn.\\n\\nAdmittedly, for the initial version of this gallery, rails was overkill: just\\nwithin the world of ruby development, Sinatra would be plenty for just an image\\ngallery and a single zipping endpoint. But server-side overkill isn\'t\\nnecessarily bad: as lost as it\'s fast and I don\'t mind paying for it (let\'s be\\nreal, my family photos aren\'t going to get millions of distinct views any day\\nsoon), there\'s no real downside[^2]. Besides:\\n\\n1. I have notions of extending the app with the ability to search and filter by\\n   name, and rails makes building out the additional models down the line quite\\n   straightforward; and\\n1. I wanted to practice working in and testing rails code for professional reasons\\n\\nSo fuck it, rails it is.\\n\\n## Open zipper?\\n\\nI searched for \\"zip\\" on [Ruby\\nToolbox](https://www.ruby-toolbox.com/search?q=zip), and found two projects\\nthat seemed to actually be intended for zipping files:\\n\\n![Rubyzip gem stats](./rubyzip-gem-stats.png)\\n\\n![Zip gem stats](./zip-gem-stats.png)\\n\\nI don\'t know how a popularity rating is calculated, but it has a Science Beaker\\nicon, so it must be important. [Rubyzip](https://github.com/rubyzip/rubyzip),\\nit seems, is the gem for me.\\n\\n## Zip it up.\\n\\nThat repo\'s `README.md` has some intro-type example code:\\n\\n```ruby\\nrequire \'rubygems\'\\nrequire \'zip\'\\n\\nfolder = \\"Users/me/Desktop/stuff_to_zip\\"\\ninput_filenames = [\'image.jpg\', \'description.txt\', \'stats.csv\']\\n\\nzipfile_name = \\"/Users/me/Desktop/archive.zip\\"\\n\\nZip::File.open(zipfile_name, Zip::File::CREATE) do |zipfile|\\n  input_filenames.each do |filename|\\n    # Two arguments:\\n    # - The name of the file as it will appear in the archive\\n    # - The original file, including the path to find it\\n    zipfile.add(filename, folder + \'/\' + filename)\\n  end\\n  zipfile.get_output_stream(\\"myFile\\") { |os| os.write \\"myFile contains just this\\" }\\nend\\n```\\n\\nIt\'s not clear from the example alone what files do and don\'t need to already\\nexist to get this to work. I fiddled around until I got a minimal POC working,\\nwhich looked something like this:\\n\\n```ruby\\n# In the Gemfile, mind, you need\\n#   gem \'rubyzip\'\\nrequire \'zip\'\\n\\nfolder = \\"/Users/ambirdsall/Desktop/actual_preexisting_directory\\"\\ninput_filenames = [\'actual_preexisting_file.png\']\\n\\nzipfile_name = \\"/Users/ambirdsall/Desktop/not_yet_existing_archive_file.zip\\"\\n\\nZip::File.open(zipfile_name, Zip::File::CREATE) do |zipfile|\\n  input_filenames.each do |filename|\\n    # Two arguments:\\n    # - The name of the file as it will appear in the archive\\n    # - The original file, including the path to find it\\n    zipfile.add(filename, folder + \'/\' + filename)\\n  end\\n  zipfile.get_output_stream(\\"new_filename_for_streamed_data.txt\\") do |os|\\n    os.write \\"I\'m a dynamically-created plain text file\\"\\n  end\\nend\\n```\\n\\nTo work inside a filesystem like this, `rubyzip` needs a full path to the\\nsource files and the zipfile\'s directory (that all throws a big error if the\\npath given to `zipfile.add` isn\'t valid); but the `zipfile_name` doesn\'t need to\\nexist yet.\\n\\nMore significantly, that `\\"new_filename_for_streamed_data\\"` business implies\\nthat the filesystem can be skipped altogether for data which can be\\nstreamed\u2014from a database, say, [or s3](https://github.com/ambirdsall/wedding_photos/blob/383ddcb249c657bfbf944533373d7d560cea11ab/app/actors/photo_fetcher.rb#L12-L16).\\n\\nThis is plenty to work with: just get a list of selected images from the UI;\\nuse that list to generate the corresponding s3 URLs; and then stream the\\ncontents of each photo into a zipfile which is then sent to the user\'s browser\\nfor download. The `zipfile.get_output_stream` trick can be used for a friendly\\nindex.txt file down the line, after I\'ve mapped each photo to the names of the\\npeople in it.\\n\\n## Coming Soon...\\n\\nI\'ll dive into the design of the UI and of the server code soon, each in its own post.\\n\\n[^1]:\\n\\n  I whipped up some `imagemagick` scripts to do batch resizing and\\n  optimizing, and hosted all the photos as public-read files in an s3 bucket.\\n\\n[^2]:\\n\\n  Certainly nothing compared to sites that make you download megabytes of\\n  javascript before the first paint on mobile."},{"id":"cron-legacy","metadata":{"permalink":"/blog/cron-legacy","source":"@site/blog/cron/index.mdx","title":"Cron: Legacy","description":"I thought it would be cool to get my computer to automatically run brew update every so","date":"2016-10-11T00:00:00.000Z","tags":[],"readingTime":7.005,"hasTruncateMarker":true,"authors":[],"frontMatter":{"slug":"cron-legacy","title":"Cron: Legacy","topic":"OSX < UNIX","date":"2016-10-11T00:00:00.000Z"},"unlisted":false,"lastUpdatedAt":1745535817000,"prevItem":{"title":"Building An Adequate Wedding Gallery","permalink":"/blog/building-an-adequate-wedding-gallery"},"nextItem":{"title":"What Does It Even Mean For The Media To Be Objective","permalink":"/blog/what-does-it-even-mean-for-the-media-to-be-objective"}},"content":"I thought it would be cool to get my computer to automatically run `brew update` every so\\noften in the background and email me if anything went wrong. I thought it would be pretty\\nsimple! It was not, in fact, prety simple: I ran into a bunch of super frustrating errors,\\nusually because I was taking some aspect of my normal terminal environment for granted\\n(the `$PATH` variable that tells the shell where to look to find commands; email protocols\\nand authentication; ssh authentication; error handling in the shell; etc etc etc).\\n\\nBut I learned a bunch in the process! So kick back, pour yourself a drink, and\\nlearn about `cron`, the old-school unix tool you can use to run programs behind\\nyour own back.\\n\\n{/* truncate */}\\n\\n## What is a `cron` and how does it... cron?\\n\\nCron is an old unix program used to run commands repeatedly on a schedule.\\nThere are two main parts to the cron system: there is the cron daemon, a\\nprogram that (once set up) is constantly running in the background; and there\\nis the crontab file, which keeps the schedule of programs to run [^1]. Once every minute\\non the minute, assuming your computer is awake and running, the cron daemon (the system\\nautomatically launches `cron` after you save your first valid crontab file, and on boot\\nafterwards) evaluates each line of all of the relevant installed crontab files, running\\nany commands whose schedules match on the current minute. Any output to `$STDERR` is\\nassumed to be an error and is mailed to you: `cron`\'s default mailing strategy is a local\\n\\"mailbox\\" originally used for pre-internet user-to-user messages within a multi-user\\nsystem, but if you\'re fancy with the google, it\'s pretty manageable to teach it to use\\nsomething like gmail instead.\\n\\n## The `crontab` file\\n\\nYou edit the crontab file with the command `crontab -e`, regardless of where\\nyou are in the filesystem. You need to do some config to use this; more on that\\nlater.\\n\\nEach line either contains a shell variable definition, in which case `cron`\\nupdates its environment accordingly[^2], or a\\nscheduled command. Scheduled commands are structured like this:\\n\\n```\\n* * * * *  /absolute/path/of/command/to/execute\\n\u2502 \u2502 \u2502 \u2502 \u2502\\n\u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500 day of week (0 - 7) (0 to 6 are Sunday to Saturday, or use names; 7 is Sunday, the same as 0)\\n\u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 month (1 - 12)\\n\u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 day of month (1 - 31)\\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 hour (0 - 23)\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 min (0 - 59)\\n```\\n\\nFor any element of a schedule (hours, minutes, etc), you can use:\\n\\n```\\n*  matches every value\\n-  defines a range, like `9-17` for every hour from 9AM to 5PM\\n,  separates multiple individual values, such as `MON,WED,FRI`\\n```\\n\\nSo, for example `0 9-17 * * 1-5` matches each hour from 9AM to 5PM on the hour,\\neach weekday, with no restrictions by month or day of month.\\n\\n## Editing `crontab` takes special config, because life is suffering\\n\\nSo `crontab -e` opens the file with whatever your have set to `$EDITOR` in your\\nshell session. I use vim, which is secretly a problem: the `crontab` program\\nsets some rules about how you save the file, and vim\'s defaults work\\ndifferently.\\n\\nSpecifically, when vim writes changes to a file, it first saves them as a\\nbackup file, then overwrites the original. This helps vim be more confident it\\nwon\'t corrupt data if it crashes partway through writing, but `crontab` won\'t\\nlet you write to anything but the file itself, in-place. To get around this,\\nadd to `~/.vimrc`:\\n\\n```vim\\nautocmd filetype crontab setlocal nobackup nowritebackup\\n```\\n\\n## `cron` doesn\'t have a lot of things I took for granted about the shell environment\\n\\nThis isn\'t that bad to deal with once you get your head around it, but it took\\nme a while to realize just how much implicit environment I rely on when working\\nin a terminal. The main one is the `$PATH` variable: for every command that\\nisn\'t built-in shell syntax, odds are good you\'ll need to prepend the `/bin/`\\nor `/usr/local/bin/` or `/usr/sbin/` or what have you. If you don\'t know the\\nfull path of some command you use a lot, for example, `git`, pop open a\\nterminal and run `which git`.\\n\\nMy first instinct was to make one of my `crontab` file\'s first lines something like\\n\\n```bash\\nPATH=/Users/ambirdsall/bin:/usr/local/bin:/usr/bin:/bin:/I/dunno/maybe/sbin:/other/things/I\'m/used/to/also\\n```\\n\\nIf my crontab environment has access to all the same stuff I use everyday in my\\nterminal, then writing a cron command is just like writing any old terminal\\ncommand. But I think that\'s the wrong approach, for two reasons:\\n\\n1. Anything more complicated than a one-liner (and even many of those), you\'re\\n   better off just saving in a shell script\\n1. If you succeed, you\'ve just hidden from yourself how things work under the\\n   hood AND made it easier for part of your terminal-based life to get out of\\n   sync.\\n\\nIf you feel a little lost when working with the full absolute paths of programs\\nand would like a better handle on why different programs live in `/bin` vs\\n\'/sbin\' vs `/usr/sbin` vs `/usr/local/bin`\u2014or even why some programs live in\\nmore than one of those places\u2014just run `man hier` in your terminal and give it\\na quick read.\\n\\n## Let\'s put almost all of it together\\n\\nDisclaimer: we\'re skipping over some hoops I had to jump through to send actual\\nemails to my gmail account from the command line (google it) and the way\\nthornier issue of how to authenticate an SSH connection with github (which is\\nwhere `brew` searches for updates) in a bare-bones scripting environment\\n(google \\"askpass\\" or go _really_ HAM and learn to use `expect`). So:\\n\\n```bash\\n0 * * * * /usr/local/bin/brew update\\n```\\n\\nwill run `brew update` every hour on the hour, every single day, with zero\\nconscious effort on my part. Awesome! Awesome.\\n\\nWait, this _is_ actually awesome, right?\\n\\n![A dumb cron error email](./dumb-cron-error-email.png)\\n\\nGoddamn it.\\n\\n## Okay, let\'s just go through _one_ of the dumb problems\\n\\nHere\'s what was going on:\\n\\n1. If everything is up to date, `brew` exits with a heads-up to `$STDERR`\\n1. Seeing a message in the error stream, `cron` emailed me\\n1. I don\'t want email alerts every hour that things are still up-to-date\\n\\nSo:\\n\\n```bash\\n/usr/local/bin/brew update 2>&1 > /dev/null | grep -v \'up-to-date\' >&2\\n```\\n\\nFirst, a quick note: I use `zsh`, not `bash`, and there are a few differences\\nin how the two shells handle redirection, so if you use `bash`, you might\\nneed to make a few changes to get it working properly\\n[^3]. Let\'s break this down:\\n\\n```bash\\n2>&1 > /dev/null\\n```\\n\\nThe `2>&1` redirects `$STDERR` to `$STDOUT`. The `> /dev/null` redirects\\n`$STDOUT` to the Pit of Despair. If you think this seems like it will redirect\\nEVERYTHING to `/dev/null`, leaving you nothing useful to work with, you think\\nlike I do. But it doesn\'t! Whatever redirections you specify don\'t take effect\\nuntil the next pipe (or the end of the pipeline if there is no next pipe). It\\nmakes sense: this system lets you redirect a bunch of things\\n[^4] to each\\nothers\' old handles at the same time without having to worry too much about\\noverwriting important data streams because of accidental collisions along the\\nway.\\n\\n```bash\\ngrep -v \'up-to-date\'\\n```\\n\\nSo it\'s the contents of `$STDERR` alone going through that pipe. Nice. `grep`\'s\\n`-v` flag reverses the pattern, meaning lines that DON\'T contain \'up-to-date\'\\nare printed. Effectively, this filters out the \'up-to-date\' error while letting\\nother errors pass through.\\n\\n```bash\\n>&2\\n```\\n\\nThe last token there, `>&2`, redirects this filtered error stream from `$STDOUT`\\nback to `$STDERR`; if anything else goes wrong, `cron` will email as it should,\\nbut it won\'t spam my inbox with nonsense just because I\'m already good.\\n\\n### NICE.\\n\\n[^1]:\\n\\n  Depending on your operating system, there might be both system-wide\\n  crontabs and user-specific crontab files; I\'m only going to discuss systems\\n  with a single crontab file here.\\n\\n[^2]:\\n\\n  Setting `$SHELL`, `$PATH`, and `$MAILTO` correctly is quite important, and\\n  worth some googling if you have questions.\\n\\n[^3]:\\n\\n  If you don\'t know what shell you\'re using, it\'s probably `bash`, but you\\n  can check by running `echo $SHELL`.\\n\\n[^4]:\\n\\n  There\'s no rule that says `$STDIN`, `$STDOUT`, and `$STDERR` are the only\\n  [file descriptors](https://en.wikipedia.org/wiki/File_descriptor) your\\n  process can have open, after all."},{"id":"what-does-it-even-mean-for-the-media-to-be-objective","metadata":{"permalink":"/blog/what-does-it-even-mean-for-the-media-to-be-objective","source":"@site/blog/what-does-it-even-mean-for-the-media-to-be-objective.mdx","title":"What Does It Even Mean For The Media To Be Objective","description":"This","date":"2016-10-04T00:00:00.000Z","tags":[],"readingTime":6.855,"hasTruncateMarker":true,"authors":[],"frontMatter":{"slug":"what-does-it-even-mean-for-the-media-to-be-objective","title":"What Does It Even Mean For The Media To Be Objective","topic":"epistemology","date":"2016-10-04T00:00:00.000Z"},"unlisted":false,"lastUpdatedAt":1745535817000,"prevItem":{"title":"Cron: Legacy","permalink":"/blog/cron-legacy"},"nextItem":{"title":"Backticks Are Fantastic Because Typing Is The Worst","permalink":"/blog/backticks-are-fantastic-because-typing-is-the-worst"}},"content":"[This](http://www.theestablishment.co/2016/09/29/the-dangerous-myth-of-media-objectivity/)\\nis a timely and important article, and it drove me absolutely crazy. Before I\\nquote anything, I think I need to do some conceptual prep work. The problem, you\\nsee, is that the article suffers from a fatal fault\u2014in calling out a false\\nnotion of objectivity, it leaves unquestioned its right to be framed as\\n\\"objectivity\\". Look, I know I might sound ridiculous, but goddamn it, ideas\\nmatter. It\'s not so much a problem because that false objectivity is bad per se\\n(though it is); it\'s a problem because a better alternative exists and I think\\ngetting it right is really, really important.\\n\\n{/* truncate */}\\n\\n## Science is not what, but how\\n\\n> \\"The first principle is that you must not fool yourself\u2013and you are the easiest person\\n> to fool.\\"\\n>\\n> \u2013Richard Feynman\\n\\nHuman brains have all sorts of shortcuts for finding patterns. It\'s our greatest talent,\\nand it\'s what\'s behind the best of us. Here are some ways to conceive of various shortcuts\\nfor finding patterns: jumping to a conclusion; conceptual leaps, both the creative\\nparallel kind and the brilliant insight kind; optical illusions; artistic license;\\nintuition; suspicions; logical fallacies; madness.\\n\\nBasically every social interaction we have, every use of language, is running on hardware\\nthat, when you get down to it, is just doing a bunch of sloppy pattern matching[^1]. And\\nwe\'re ridiculously good at it! It has literally taken us to [the\\nmoon](http://joshworth.com/dev/pixelspace/pixelspace_solarsystem.html). But if jumping to\\nconclusions is fundamental to being an alive human, it means we\'re never going to not be\\nwrong about some stuff. You, me, Einstein, Pedro Martinez, Aristotle, Lupita Nyong\'o:\\neveryone who ever has or will live is wrong about a ton of shit.\\n\\nThis is almost all you need to acquire a deep understanding of science. The other part is\\na way out: using statistics and measurements of the actual world to verify\\nstuff. Human perception isn\'t perfect, but it\'s still pretty good, and the\\nphysical universe makes sense. You take your flawed conceptions as a starting\\npoint, and you see which ones you can try to disprove. I say \\"try\\", because a\\nlot of times, you can\'t even do that: the world is full of questions that have\\na single true, reality-based answer that there\'s no way to find out. Got to\\nhope there\'s Wikipedia in Heaven. But sometimes you CAN check. So you do.\\n\\nHere\'s the last catch: you can\'t really prove anything is true, but sometimes, when the\\nfacts cooperate, you can prove things false. So you try to prove everything you believe to\\nbe true to be false. Occasionally, to your chagrin, you will be successful. And for\\ncenturies, this has been the method of human progress: shuffling painfully towards the\\ntruth by discarding convincing bullshit one piece at a time.\\n\\nThat\'s the whole trick. That\'s how we got spaceships and vaccines. Until you go measure\\nthe real world, everybody\'s words are just words, and, as previously discussed, we are all\\nwrong about a lot of things. Shit, we didn\'t even need to bring up intentional lying or\\nwillful ignorance: even if everyone is trying their very best, people alone can\'t be\\nrelied on for truth. No folk tradition managed to invent antibiotics, you know?\\n\\n## What that article means when it says \\"objectivity\\"\\n\\nDefining \\"objectivity\\" in terms of empirical truth, the following paragraph\\nbecomes absurd:\\n\\n> Is it the media\u2019s responsibility to cover groups or persons who purposefully use hateful\\n> and provocative speech as a means to gain attention? In what way should this coverage\\n> manifest? And, perhaps most importantly\u2014at what point are journalists obligated to\\n> repudiate notions of objectivity for the sake of humanity and morality?\\n\\nHumanity and morality are, in general, best served by dilligent, unassuming\\nrespect for empirical truth. Furthermore, whether a thing is true or false has\\nlittle to do with whether it\'s good or bad[^2], and vice versa.\\n\\nThe most frustrating part of writing this is that I haven\'t found a way not to\\ncome down too harshly. The article is talking about the same problem I am, and\\nin many ways it\'s doing quite a good job of it. While it doesn\'t properly name\\nthe concept it targets, it pins it down precisely through a series of incisive\\nand well-sourced takedowns of media uncritically airing people who are\\ndemonstrably in the wrong:\\n\\n> The Milo profile was far from the first time that an outlet has, I\u2019d argue, favored an\\n> obscure notion of objectivity over the protection of human rights and civil liberties. In\\n> May, USA Today [printed](http://www.usatoday.com/story/opinion/2016/05/02/boycott-target-american-family-association-editorials-debates/83848878/) an op-ed written by the president of the American Family\\n> Association (AFA), Tim Wildmon, urging readers to boycott the discount retailer Target due\\n> to their inclusive bathroom [policy](https://corporate.target.com/article/2016/04/target-stands-inclusivity#sf45842864).\\n> USA Today neglected to inform its readers that AFA is\\n> [an anti-LGBT hate group](https://www.splcenter.org/fighting-hate/extremist-files/group/american-family-association), while also providing a space for Wildmon to perpetuate the\\n> \u201cbathroom predator\u201d myth. Not only has this virulent lie been [disproven](http://mediamatters.org/research/2016/05/05/comprehensive-guide-debunked-bathroom-predator-myth/210200), its infectious\\n> reach has had a documented [impact](http://www.advocate.com/transgender/2016/7/13/survey-shows-how-trans-bathroom-predator-myth-hurts-real-people) on the psychological and physical safety of the\\n> transgender community.\\n\\nThe problem is that that \\"obscure notion of objectivity\\" is neither obscure nor,\\nI would argue, objectivity. I suspect, if asked to define \\"media objectivity\\", a\\nlot of Americans would sketch out a concept similar to this: an objective media\\ndoes not try to shape events, it merely reports on them. I suspect FAR more\\nstrongly that this is how the American media itself sees its mission. If the\\npitfall to be avoided is a thumb on the scales, then you\'re at the mercy of the\\nexisting terms of debate; which is at the mercy of what humans believe; which,\\nc\'mon, we\'ve been over that already. Like [400 years\\nago](https://www.gutenberg.org/files/5500/5500-h/5500-h.htm) already. But for\\nall the \\"obscure notion\\" shade it\'s trying to throw, the article doesn\'t\\nchallenge that as the framework for judging \\"objectivity\\". And as long as that\'s\\nin place, journalists either have to err on the side of not being to critical or\\nthey need to get rid of \\"objectivity\\" as the primary standard. And that\'s\\nhogwash.\\n\\n## Why that\'s a problem\\n\\nThat definition needs to be demoted to the second concern: the primary metric by which the\\nmedia\'s objectivity should be measured is integrity with objective reality as best we can\\nmeasure it. Often that means statistics. It means fact-checking is not a \\"nice-to-have\\",\\nit is fundamental to the whole operation. Really, it means doing some fucking reporting.\\n\\nThe article quotes [Lisa\\nWade](https://thesocietypages.org/socimages/2015/04/09/racial-bias-and-media-coverage-of-violent-crime/),\\na sociology professor at Occidental:\\n\\n> \u201cEach time we see a black person on TV who is linked with a violent crime or portrayed\\n> as a criminal, the neurons in our brain that link blackness with criminality fire. The\\n> more often a link is triggered, the stronger it becomes. Disproportionate reporting . . .\\n> make the neural links in our brain\u2014its actual physical structure\u2014reflect the racism\\n> inherent in the reporting itself.\u201d\\n\\nThe argument, which I find quite compelling, is that repeating socially-backed but\\ndamaging, false, or repugnant rhetoric, ESPECIALLY uncritically, reinforces it in the\\naudience\'s minds, corroding truth and/or the common good. But that logic seems awfully\\nopen to extension: repeating this implicit notion that objective balance in a conflict is\\nprimarily determined by the social force of one or another \\"side\\", rather than by its\\nverifiable truth[^3] literally builds that link in\\nreaders\' minds. People use words the same way the folks around them do: for the sake of\\nthe people around us, America has to step up at using them in service of truth.\\n\\n[^1]:\\n\\n  European philosophy has spent lifetimes failing to get around this fact,\\n  which is why it is so [beautiful](http://www.fullbooks.com/The-Ethics.html)\\n  and so\\n  [tedious](https://tractatus-online.appspot.com/Tractatus/jonathan/index.html).\\n\\n[^2]:\\n\\n  The most pernicious form this takes is \\"we can\'t change `$THING` because\\n  that\'s just the way things are\\". Beyond the surface-level problem of\\n  squelching analysis of `$THING` in good/bad terms because of a tautological\\n  assertion of its truth value, it nihilistically sweeps away any reasonable\\n  question of the upside risk of attempting to change `$THING` _and_ it\'s\\n  almost always wrong, historically speaking.\\n\\n[^3]: It is always both, of course, for we are awash in a sea of opinions."},{"id":"backticks-are-fantastic-because-typing-is-the-worst","metadata":{"permalink":"/blog/backticks-are-fantastic-because-typing-is-the-worst","source":"@site/blog/backticks-in-zsh-are-fantastic/index.mdx","title":"Backticks Are Fantastic Because Typing Is The Worst","description":"Backticks Are Fantastic","date":"2016-09-20T00:00:00.000Z","tags":[],"readingTime":1.17,"hasTruncateMarker":true,"authors":[],"frontMatter":{"slug":"backticks-are-fantastic-because-typing-is-the-worst","title":"Backticks Are Fantastic Because Typing Is The Worst","category":"Dev Environment","topic":"zsh","date":"2016-09-20T00:00:00.000Z"},"unlisted":false,"lastUpdatedAt":1745535817000,"prevItem":{"title":"What Does It Even Mean For The Media To Be Objective","permalink":"/blog/what-does-it-even-mean-for-the-media-to-be-objective"},"nextItem":{"title":"Locks Are Some Shit","permalink":"/blog/locks-are-some-shit"}},"content":"## Backticks Are Fantastic\\n\\nI mean, [legit\\nawesome](http://www.refining-linux.org/archives/44/ZSH-Gem-10-Backtick-expansion/).\\nHere\'s a contrived recreation of a real-world example I encountered:\\n\\n![animated demonstration of backtick expansion in zsh](./ln_backticks.gif)\\n\\nLet\'s break this down. {/* truncate */} When making a symbolic link, you should type out the absolute path to the\\nlink target. There are valid reasons for that behavior (though I\'d prefer `ln` just\\nexpanded relative links before making the symlink, tbh), but a lot of directory names are\\na hassle to type out. Everyone who\'s worked in a JVM language feels me.\\n\\nTwo things help:\\n\\n1. If, as is often the case, you want to link to go in your current directory, you can totally omit the second argument\\n1. Typing some shell expression inside backticks which generates the path. If you use `bash`, you just have to trust your short-term memory, but hitting `tab` expands that expression interactively in `zsh`. You use `zsh`, right?\\n\\nSome would argue that the `$()` subshell operator has strictly more powerful semantics than\\nbackticks because it can be nested; they are, of course, correct. Other people like subshells\\nbecause when you nest them, it reads just like lisp code; they are, of course, nerds[^1]. When you don\'t\\nhave to nest anything, though, backticks have a killer advantage over subshells:\\n\\n1. 33% fewer keystrokes\\n\\nChoose your own adventure.\\n\\n[^1]:\\n\\n  When it comes to lisp, I am, of course, [a gigantic\\n  nerd](https://github.com/ambirdsall/moon-phase) myself."},{"id":"locks-are-some-shit","metadata":{"permalink":"/blog/locks-are-some-shit","source":"@site/blog/locks/index.mdx","title":"Locks Are Some Shit","description":"I\'ve been reading [Operating Systems: Three Easy","date":"2016-09-01T00:00:00.000Z","tags":[{"inline":true,"label":"operating_systems","permalink":"/blog/tags/operating-systems"},{"inline":true,"label":"concurrency","permalink":"/blog/tags/concurrency"},{"inline":true,"label":"locks","permalink":"/blog/tags/locks"}],"readingTime":8.34,"hasTruncateMarker":true,"authors":[],"frontMatter":{"slug":"locks-are-some-shit","title":"Locks Are Some Shit","category":"operating_systems","topic":"concurrency","date":"2016-09-01T00:00:00.000Z","tags":["operating_systems","concurrency","locks"]},"unlisted":false,"lastUpdatedAt":1745535817000,"prevItem":{"title":"Backticks Are Fantastic Because Typing Is The Worst","permalink":"/blog/backticks-are-fantastic-because-typing-is-the-worst"},"nextItem":{"title":"Berkely DB Design Lessons","permalink":"/blog/berkely-db-design-lessons"}},"content":"I\'ve been reading [Operating Systems: Three Easy\\nPieces](http://pages.cs.wisc.edu/~remzi/OSTEP). I highly recommend the book if\\nyou\'re cool fiddling with C a bit. Actually, scratch that: I recommend the book\\nif you ever write code that runs on a server or any other linux/osx environment,\\n_especially_ if you feel a little out of your depth with C. The code examples\\nare not that intimidating, even if you don\'t know from typecasting or a pointer\\n(okay, learning the difference between `foo`, `*foo` and `&foo` is useful, but\\nnot knowing it doesn\'t prevent you from getting the gist of the code samples),\\nand getting a deeper understanding of the environment your code works in will\\nmake a lot of known unknowns come into a bit more focus. Honest.\\n\\n{/* truncate */}\\n\\nThe first of the three parts was memory virtualization: that is, how computing\\ntime and resources get divvied up amongst processes. There was some fascinating\\nstuff in there: the API for forking a new process, for instance, is weirder and\\ncooler than I expected, and learning the topography of the boundary between the\\nOS and application code (such as `ls` or `Google Chrome.app`) is rad. And then\\nthere are parts that are totally internal, though vital, to the kernel. Nothing\\nagainst free space management, segmentation, or the five whole chapters on\\nmemory paging, but I\'m just not as interested in the kernel\'s implementation as\\nits interface.\\n\\nI kept wondering if I would be better off just jumping straight to concurrency,\\nbecause that\'s what I was really pumped to learn. Would I be missing out on some\\nlogically necessary information if I skipped them?? (Nope.) Learn from my\\nmistake and jump to the shit you find interesting, because someday you\'re going\\nto die. So: [locks](http://pages.cs.wisc.edu/~remzi/OSTEP/threads-locks.pdf)!\\n\\n## I Don\'t Need No Stinkin\' Lock\\n\\nLocks are what keep multiple threads, running in parallel, from fucking each\\nother up when dealing with a shared bit of state. There is almost no operation\\ntoo small for these little bastards to mess up, given the chance. Take this:\\n\\n```c\\nstatic volatile int counter = 0;\\n\\nvoid *mythread(void *arg) {\\n  int i;\\n  for (i = 0; i < 100000; i++) {\\n    counter++;\\n  }\\n  return NULL;\\n}\\n```\\n\\nBecause I had to look it up: `volatile` is a keyword that prevents certain\\ncompiler optimizations from happening, specifically for things like this shared\\ncounter.\\n\\nSo, there\'s a shared counter and there\'s a procedure that uses it suitable for\\ngiving to a couple threads. I extracted all the code dealing with that shared\\nbit of state:\\n\\n```c\\ncounter++\\n```\\n\\nThat\'s it! A single line, with a single unary operator. How unsafe can THAT be?\\nLet\'s add some logging and fire up a couple threads:\\n\\n```c\\n#include <stdio.h>\\n#include <pthread.h>\\n\\nstatic volatile int counter = 0;\\n\\nvoid *mythread(void *arg) {\\n  printf(\\"%s: begin\\\\n\\", (char *) arg);\\n  int i;\\n  for (i = 0; i < 100000; i++) {\\n    counter++;\\n  }\\n  printf(\\"%s: end\\\\n\\", (char *) arg);\\n  return NULL;\\n}\\n\\nint main(int argc, char *argv[]) {\\n  pthread_t p1, p2;\\n  printf(\\"main: begin (counter = %d)\\\\n\\", counter);\\n\\n  pthread_create(&p1, NULL, mythread, \\"A\\");\\n  pthread_create(&p2, NULL, mythread, \\"B\\");\\n\\n  // wait for them fucks to finish\\n  pthread_join(p1, NULL);\\n  pthread_join(p2, NULL);\\n\\n  printf(\\"main: done with both (counter = %d)\\", counter);\\n  return 0;\\n}\\n```\\n\\nSo. `counter` starts at 0, and then two threads each run `counter++` 100,000\\ntimes apiece. That makes 200,000, right?\\n\\n```\\nmain: begin (counter = 0)\\nA: begin\\nB: begin\\nB: end\\nA: end\\nmain: done with both (counter = 100745)\\n```\\n\\nINTERESTING.\\n\\nThe trouble is that `counter++` is _three_ operations, not one:\\n\\n1. Get the value of `counter` out of whatever register it\'s stored in\\n2. Increment that value by one\\n3. Store the new value in that register\\n\\nSo `p2` reads the value of `counter`\'s register at, e.g., 17; then it increments\\nthe value to 18; at the same time as `p2` is doing that incrementing, one core\\nover, `p1` reads that same register, which is still 17. In parallel, each adds\\none to the value it read and stores that new value in the register, and lo: 17 +\\n1 + 1 = 18.\\n\\n## Lock That Shit Down\\n\\nSo let\'s suppose you give a shit about the integrity of basic arithmetic in\\nyour code. The above nonsense won\'t do at all. I ran it eight times (you can,\\ntoo! Just stick the code above in a file (say, `bad_math.c`), compile it with\\nsomething like `gcc -o bad_math bad_math.c`, and go hog wild), with the following\\nresults:\\n\\n```\\nABAB 127499\\nABAB 144926\\nABAB 116942\\nABBA 102988\\nABBA 100745\\nABAB 114188\\nAABB 200000\\nABBA 104161\\n\\navg. 126431\\n```\\n\\nI\'m honestly pretty shocked that one run actually got 200,000. (As a sidenote,\\nit looks like the `ABAB` pattern of thread starts/finishes performs better than\\n`ABBA`, with respective averages of 125888 and 102631. `AABB`, of course, will\\nalways get 200,000 (as would `BBAA`, but `A` gets kicked off first by\\nsynchronous code).)\\n\\nSo let\'s lock this shit down. `main` doesn\'t need to change at all: we just need\\nto initialize a commonly available lock, and use it in the `mythread` procedure\\nto ensure that only one thread at a time can access the critical section (that\'s\\nthe term, coined by Dijkstra, for a section of code dealing with shared memory;\\nhere, `counter++`). Here\'s the most vanilla implementation for a POSIX system:\\n\\n```c\\nstatic volatile int counter = 0;\\npthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;\\n\\nvoid *mythread(void *arg) {\\n  printf(\\"%s: begin\\\\n\\", (char *) arg);\\n  int i;\\n  for (i = 0; i < 100000; i++) {\\n    pthread_mutex_lock(&lock);\\n    counter += 1;\\n    pthread_mutex_unlock(&lock);\\n  }\\n  printf(\\"%s: end\\\\n\\", (char *) arg);\\n  return NULL;\\n}\\n```\\n\\nNo need for extra headers; as you probably gathered from the naming, that\\nlocking mechanism is part of `pthread.h`. When any thread calls\\n`pthread_mutex_lock(&foo)` for a lock `foo`, one of two things happens: if no\\none else has the lock, it runs the critical section; or, if another thread has\\nthe lock, it waits for that thread to call `pthread_mutex_unlock(&foo)` and THEN\\ndoes its thing.\\n\\nAs you might expect, this version gets 200,000 every time (but don\'t believe\\nme...). So what\'s going on under the hood?\\n\\n## Under The Hood\\n\\nA huge disclaimer before we start playing around with implementing our own\\nlocks: this shit does not work. Checking some value to determine if a lock is in\\nuse and updating that value to secure that lock takes multiple operations, and\\nat the application level, there\'s no way to ensure that that happens atomically.\\nIn a real lock, the hardware exposes a prebundled set of operations that can be\\ncalled from a C API.\\n\\nDepending on your machine, those prebundled operations might look, if you\\nsquint, a little something like this:\\n\\n```c\\ntypedef struct __lock_t {\\n  int flag;\\n} lock_t;\\n\\nvoid init(lock_t *lock) {\\n  // 0 => lock is available, 1 => lock is held\\n  lock->flag = 0;\\n}\\n\\nint compare_and_swap(int *old_ptr, int expected, int new) {\\n  int actual = *old_ptr;\\n  if (actual == expected)\\n    *old_ptr = new;\\n  return actual;\\n}\\n\\nvoid lock(lock_t *lock) {\\n  /* while (compare_and_swap(&lock->flag, 0, 1) == 1) */\\n  while (compare_and_swap(&lock->flag, 0, 1) == 1)\\n    ; // do butt-ass nothing until that lock gets released\\n}\\n\\nvoid unlock(lock_t *lock) {\\n  lock->flag = 0;\\n}\\n```\\n\\nThis is a shitty lock for a few reasons:\\n\\n1. If the lock is taken, the thread just wastes CPU cycles until the CPU\\n   scheduler decides to let the locking thread finish its work\\n1. It\'s possible to have a thread that \\"starves\\": i.e. never, ever gets the lock\\n1. It does not work.\\n\\nBut _how badly_ does it not work?\\n\\n```\\nABAB 156000\\nABAB 103114\\nABAB 129168\\nABBA 101519\\nABBA 114152\\nABAB 103095\\nABBA 100576\\nABAB 101809\\n\\navg. 113679\\n```\\n\\nSo, I mean, that\'s a worse average than no lock at all, but there was that fluky\\n200,000 in there. Without the outlier, it would look a lot wors-\\n\\n```\\navg. 115921\\n```\\n\\nOh. From an analytical perspective, there are more steps in `compare_and_swap`\\nthan in `counter++`, so there are more places for a malicious CPU scheduler to\\nfuck with things; from a statistical perspective, we\'re nowhere near solid\\nground for declaring a winner in the contest of \\"no locks vs useless locks\\";\\nfrom an engineering perspective, please just use `pthread_mutex_t` locks.\\n\\nThere is a glimmer of hope in the book before we totally close the book on\\nsoftware locking:\\n\\n![A lock written from x86 assembly instructions](./better_lock.png)\\n\\nSeems easy enough. Take the busted lock, swap in the new `CompareAndSwap`\\nimplementation, however the fuck that works (looks like its evaluating literal\\nstrings as assembly language, but I\'m in way over my head here), and give that a\\ntest run:\\n\\n```\\nABAB 141034\\nABAB 128868\\nABAB 149149\\nABAB 133336\\nABAB 165496\\nABAB 130632\\nABAB 163608\\nABAB 163309\\n\\navg. 146929\\n```\\n\\nNot half bad\\\\*!\\n\\n\\\\* Almost exactly half bad\\n\\nThat\'s all I got rght now on locks.\\n\\n## A Brief Aside About C\\n\\nWorking in C feels like working with a database to me: the fundamental way to\\ndefine the shape of your data is a struct: a behaviorless mapping of typed data\\nfields to names, just like a table in a relational database.\\n\\nNow, it\'s more complicated than that, of course, and C is a good bit more\\nexpressive than SQL. For instance, you could use the convention of pointing\\ncertain fields at integers that are pointers to the memory address of functions\\nand use them to call those functions (I believe that\'s how C++ classes work\\nunder the hood, but don\'t quote me on that as an authority).\\n\\n## Stuff In This Chapter That I Left Out\\n\\n- Various tradeoffs in balancing fairness and performance while maintaining\\n  mutual exclusion (thus, incidentally, the term \\"mutex\\")\\n- Some interesting historical locking mechanisms\\n- Some background on what the hardware does and doesn\'t do, and what that means\\n  for the OS\\n- A cool-ass locking implementation from the linux kernel that tracks both the\\n  status of the lock and the size of its queue with a single integer"},{"id":"berkely-db-design-lessons","metadata":{"permalink":"/blog/berkely-db-design-lessons","source":"@site/blog/berkeley_db.mdx","title":"Berkely DB Design Lessons","description":"Notes taken while reading the Berkeley DB section","date":"2016-08-31T00:00:00.000Z","tags":[{"inline":true,"label":"quotes","permalink":"/blog/tags/quotes"},{"inline":true,"label":"design","permalink":"/blog/tags/design"},{"inline":true,"label":"architecture","permalink":"/blog/tags/architecture"}],"readingTime":9.84,"hasTruncateMarker":true,"authors":[],"frontMatter":{"slug":"berkely-db-design-lessons","title":"Berkely DB Design Lessons","topic":"quotes","date":"2016-08-31T00:00:00.000Z","tags":["quotes","design","architecture"]},"unlisted":false,"lastUpdatedAt":1745535817000,"prevItem":{"title":"Locks Are Some Shit","permalink":"/blog/locks-are-some-shit"}},"content":"Notes taken while reading the [Berkeley DB](http://www.aosabook.org/en/bdb.html) section\\nof [The Architecture of Open-Source Applications](http://www.aosabook.org/en/index.html),\\nwhich breaks up its discussion of the application\'s specific architecture with general\\nlessons and aphorisms. Read the whole thing, it\'s great.\\n\\n{/* truncate */}\\n\\nThere\'s a grimness to these that I find utterly charming: [lesson\\n3](#design-lesson-3) warns \\"[s]oftware architecture degrades in direct\\nproportion to the number of changes made to the software: bug fixes corrode the\\nlayering and new features stress design.\\" It\'s an approach that treats software\\ndesign in general and object orientation in specific (OO as in \\"code that goes\\n\'not my job, you figure it out\'\\", not as in \\"code that is organized with\\nclasses\\") not like a matter of artistic composition so much as intellectual\\nsanitation. It\'s a dirty world out there: wash your ass.\\n\\n---\\n\\n## Design Lesson 1\\n\\n> It is vital for any complex software package\'s testing and maintenance that the\\n> software be designed and built as a cooperating set of modules with\\n> well-defined API boundaries. The boundaries can (and should!) shift as needs\\n> dictate, but they always need to be there. The existence of those boundaries\\n> prevents the software from becoming an unmaintainable pile of spaghetti. Butler\\n> Lampson once said that all problems in computer science can be solved by\\n> another level of indirection. More to the point, when asked what it meant for\\n> something to be object-oriented, Lampson said it meant being able to have\\n> multiple implementations behind an API. The Berkeley DB design and\\n> implementation embody this approach of permitting multiple implementations\\n> behind a common interface, providing an object-oriented look and feel, even\\n> though the library is written in C.\\n\\n## Design Lesson 2\\n\\n> A software design is simply one of several ways to force yourself to think\\n> through the entire problem before attempting to solve it. Skilled programmers\\n> use different techniques to this end: some write a first version and throw it\\n> away, some write extensive manual pages or design documents, others fill out a\\n> code template where every requirement is identified and assigned to a specific\\n> function or comment. For example, in Berkeley DB, we created a complete set of\\n> Unix-style manual pages for the access methods and underlying components before\\n> writing any code. Regardless of the technique used, it\'s difficult to think\\n> clearly about program architecture after code debugging begins, not to mention\\n> that large architectural changes often waste previous debugging effort.\\n> Software architecture requires a different mind set from debugging code, and\\n> the architecture you have when you begin debugging is usually the architecture\\n> you\'ll deliver in that release.\\n\\n## Design Lesson 3\\n\\n> Software architecture does not age gracefully. Software architecture degrades\\n> in direct proportion to the number of changes made to the software: bug fixes\\n> corrode the layering and new features stress design. Deciding when the software\\n> architecture has degraded sufficiently that you should re-design or re-write a\\n> module is a hard decision. On one hand, as the architecture degrades,\\n> maintenance and development become more difficult and at the end of that path\\n> is a legacy piece of software maintainable only by having an army of\\n> brute-force testers for every release, because nobody understands how the\\n> software works inside. On the other hand, users will bitterly complain over the\\n> instability and incompatibilities that result from fundamental changes. As a\\n> software architect, your only guarantee is that someone will be angry with you\\n> no matter which path you choose.\\n\\n## Design Lesson 4\\n\\n> It doesn\'t matter how you name your variables, methods, functions, or what\\n> comments or code style you use; that is, there are a large number of formats\\n> and styles that are \\"good enough.\\" What does matter, and matters very much, is\\n> that naming and style be consistent. Skilled programmers derive a tremendous\\n> amount of information from code format and object naming. You should view\\n> naming and style inconsistencies as some programmers investing time and effort\\n> to lie to the other programmers, and vice versa. Failing to follow house coding\\n> conventions is a firing offense.\\n\\n## Design Lesson 5\\n\\n> Software architects must choose their upgrade battles carefully: users will\\n> accept minor changes to upgrade to new releases (if you guarantee compile-time\\n> errors, that is, obvious failures until the upgrade is complete; upgrade\\n> changes should never fail in subtle ways). But to make truly fundamental\\n> changes, you must admit it\'s a new code base and requires a port of your user\\n> base. Obviously, new code bases and application ports are not cheap in time or\\n> resources, but neither is angering your user base by telling them a huge\\n> overhaul is really a minor upgrade.\\n\\n## Design Lesson 6\\n\\n> In library design, respect for the namespace is vital. Programmers who use your\\n> library should not need to memorize dozens of reserved names for functions,\\n> constants, structures, and global variables to avoid naming collisions between\\n> an application and the library.\\n\\n## Design Lesson 7\\n\\n> Before we wrote a shared-memory linked-list package, Berkeley DB engineers\\n> hand-coded a variety of different data structures in shared memory, and these\\n> implementations were fragile and difficult to debug. The shared-memory list\\n> package, modeled after the BSD list package (queue.h), replaced all of those\\n> efforts. Once it was debugged, we never had to debug another shared memory\\n> linked-list problem. This illustrates three important design principles: First,\\n> if you have functionality that appears more than once, write the shared\\n> functions and use them, because the mere existence of two copies of any\\n> specific functionality in your code guarantees that one of them is incorrectly\\n> implemented. Second, when you develop a set of general purpose routines, write\\n> a test suite for the set of routines, so you can debug them in isolation.\\n> Third, the harder code is to write, the more important for it to be separately\\n> written and maintained; it\'s almost impossible to keep surrounding code from\\n> infecting and corroding a piece of code.\\n\\n## Design Lesson 8\\n\\n> Write-ahead logging is another example of providing encapsulation and layering,\\n> even when the functionality is never going to be useful to another piece of\\n> software: after all, how many programs care about LSNs in the cache?\\n> Regardless, the discipline is useful and makes the software easier to maintain,\\n> test, debug and extend.\\n\\n## Design Lesson 9\\n\\n> Berkeley DB\'s choice to use page-level locking was made for good reasons, but\\n> we\'ve found that choice to be problematic at times. Page-level locking limits\\n> the concurrency of the application as one thread of control modifying a record\\n> on a database page will prevent other threads of control from modifying other\\n> records on the same page, while record-level locks permit such concurrency as\\n> long as the two threads of control are not modifying the same record.\\n> Page-level locking enhances stability as it limits the number of recovery paths\\n> that are possible (a page is always in one of a couple of states during\\n> recovery, as opposed to the infinite number of possible states a page might be\\n> in if multiple records are being added and deleted to a page). As Berkeley DB\\n> was intended for use as an embedded system where no database administrator\\n> would be available to fix things should there be corruption, we chose stability\\n> over increased concurrency.\\n\\n## Design Lesson 10\\n\\n> Berkeley DB\'s general-purpose design was well rewarded when we added concurrent\\n> data store functionality. Initially Berkeley DB provided only two modes of\\n> operation: either you ran without any write concurrency or with full\\n> transaction support. Transaction support carries a certain degree of complexity\\n> for the developer and we found some applications wanted improved concurrency\\n> without the overhead of full transactional support. To provide this feature, we\\n> added support for API-level locking that allows concurrency, while guaranteeing\\n> no deadlocks. This required a new and different lock mode to work in the\\n> presence of cursors. Rather than adding special purpose code to the lock\\n> manager, we were able to create an alternate lock matrix that supported only\\n> the lock modes necessary for the API-level locking. Thus, simply by configuring\\n> the lock manager differently, we were able provide the locking support we\\n> needed. (Sadly, it was not as easy to change the access methods; there are\\n> still significant parts of the access method code to handle this special mode\\n> of concurrent access.)\\n\\n## Design Lesson 11\\n\\n> When you find an architectural problem you don\'t want to fix \\"right now\\" and\\n> that you\'re inclined to just let go, remember that being nibbled to death by\\n> ducks will kill you just as surely as being trampled by elephants. Don\'t be too\\n> hesitant to change entire frameworks to improve software structure, and when\\n> you make the changes, don\'t make a partial change with the idea that you\'ll\\n> clean up later\u2014do it all and then move forward. As has been often repeated, \\"If\\n> you don\'t have the time to do it right now, you won\'t find the time to do it\\n> later.\\" And while you\'re changing the framework, write the test structure as\\n> well.\\n\\n## Design Lesson 12\\n\\n> Mpool and Log use internal handle methods to facilitate write-ahead logging,\\n> and in some cases, the method declaration is longer than the code it runs,\\n> since the code is often comparing two integral values and nothing more. Why\\n> bother with such insignificant methods, just to maintain consistent layering?\\n> Because if your code is not so object-oriented as to make your teeth hurt, it\\n> is not object-oriented enough. Every piece of code should do a small number of\\n> things and there should be a high-level design encouraging programmers to build\\n> functionality out of smaller chunks of functionality, and so on. If there\'s\\n> anything we have learned about software development in the past few decades, it\\n> is that our ability to build and maintain significant pieces of software is\\n> fragile. Building and maintaining significant pieces of software is difficult\\n> and error-prone, and as the software architect, you must do everything that you\\n> can, as early as you can, as often as you can, to maximize the information\\n> conveyed in the structure of your software.\\n\\n## Design Lesson 13\\n\\n> There is rarely such thing as an unimportant bug. Sure, there\'s a typo now and\\n> then, but usually a bug implies somebody didn\'t fully understand what they were\\n> doing and implemented the wrong thing. When you fix a bug, don\'t look for the\\n> symptom: look for the underlying cause, the misunderstanding, if you will,\\n> because that leads to a better understanding of the program\'s architecture as\\n> well as revealing fundamental underlying flaws in the design itself.\\n\\n## Design Lesson 14\\n\\n> Database recovery is a complex topic, difficult to write and harder to debug\\n> because recovery simply shouldn\'t happen all that often. In his Turing Award\\n> Lecture, Edsger Dijkstra argued that programming was inherently difficult and\\n> the beginning of wisdom is to admit we are unequal to the task. Our goal as\\n> architects and programmers is to use the tools at our disposal: design, problem\\n> decomposition, review, testing, naming and style conventions, and other good\\n> habits, to constrain programming problems to problems we can solve."}]}}')}}]);